{
 "metadata": {
  "name": "",
  "signature": "sha256:5f549860375e461139eb2d72e28f1e3272ee565519058bfc3dd2ce4457642be0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Explanation</h3>\n",
      "\n",
      "This is a crude actionable strategy that makes use of the GDP Forecast dataset. The goal is to buy long/short certain securities that we believe will be effected by a change in GDP Forecast. The theory here is that the earnings of the largest publicly traded companies makes up some material component of GDP. A forecasted increase in GDP should correlate with expected increase in earnings of the companies that contribute to it. If we can predict a directional change in GDP forecast for a given period of time, we should be able to anticipate directional change of certain securities for that same period.\n",
      "\n",
      "<h3>Strategy:</h3>\n",
      "\n",
      "Use the logistic regression model to predict the probability that GDP forecasts for a given month will increase or decrease reative to the previous month. If the model meets some pre-determined confidence threshold for the predicted directional change, take action buy buying long or short a portfolio of securities that represnets the market overall. Hold the portfolio for the duration of the month, exiting each position at the end of the month.\n",
      "\n",
      "<h3>Notes:</h3>\n",
      "\n",
      "- This strategy assumes there are no transaction costs. \n",
      "- For simplicity, in this example I'm using two indices that represent the performance of the Nasdaq and S&P, rather than individual company shares, ETFs, or mutual funds.\n",
      "- I am not sure what day the GDP Forecasts used here are released each month. With more information I could better model the relationship between GDP forecast releases and changes in market value of certain securities. For illustration and simplicity, in each period an action is taken it is assumed a security is bought in the first day of the month and sold in the last day.\n",
      "\n",
      "<h3>Results:</h3>\n",
      "\n",
      "This model generated an annual return of nearly 10% with the test data set.\n",
      "\n",
      "<h3>Improvements:</h3>\n",
      "- The strategy requires that all positions are exited at the end of the month. A more sophisitcated strategy would consider holding the position at the end of the month, based on expected subsequent GDP Forecast change.\n",
      "- The model assumes that the same dollar value is invested in each period when an action is taken, regardless of the model's confidence in GDP Forecast change. A more sophisticated model would augment investment to reflect varying confidence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import libraries\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import pandas.io.data as web\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 515
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn import svm\n",
      "from sklearn import preprocessing\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.decomposition import PCA, RandomizedPCA\n",
      "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score, accuracy_score, log_loss\n",
      "\n",
      "class Model(object):\n",
      "\n",
      "    def __init__(self, Xs, ys, model=None, scale=True, components=None):\n",
      "        \n",
      "        self.Xs = Xs \n",
      "        self.scaler = None\n",
      "        self.pca = None\n",
      "        \n",
      "        if scale:\n",
      "            # normalize data, convert to z-scores\n",
      "            self.scaler = preprocessing.StandardScaler().fit(Xs)\n",
      "            self.Xs = self.scaler.transform(Xs)\n",
      "            \n",
      "        if components:\n",
      "            # reduce dimensionality of Xs\n",
      "            self.pca = PCA(n_components=components)\n",
      "            self.Xs = self.pca.fit_transform(self.Xs)\n",
      "            \n",
      "        self.ys = ys\n",
      "        self.model = model\n",
      "    \n",
      "    def preprocess_Xs(self, Xs):\n",
      "        # apply trained/fit model to new data set\n",
      "        if self.scaler:\n",
      "            # input data will be scaled\n",
      "            Xs = self.scaler.transform(Xs)\n",
      "        if self.pca:\n",
      "            # input dimensionality will be reduced\n",
      "            Xs = self.pca.transform(Xs)\n",
      "        return Xs\n",
      "    \n",
      "    def predict(self, X_test):\n",
      "        X_test = self.preprocess_Xs(X_test)\n",
      "        predicted = self.model.predict(X_test)\n",
      "        return predicted\n",
      "    \n",
      "    def simple_split_test(self):    \n",
      "        # split data set into train and test sets, keeping most recent data for test set\n",
      "        # return model accuracy\n",
      "        sample_count = int(math.floor(len(master)*0.25))\n",
      "        X_train = self.Xs[:-sample_count-1]\n",
      "        y_train = self.ys[:-sample_count-1]\n",
      "        X_test = self.Xs[-sample_count:]\n",
      "        y_test = self.ys[-sample_count:]\n",
      "        \n",
      "        self.model.fit(X_train, y_train)\n",
      "        predicted = self.model.predict(X_test)\n",
      "        \n",
      "        scores = {\n",
      "        'explained_variance_score': '%0.2f' % explained_variance_score(y_test, predicted),\n",
      "        'mean_absolute_error': '%0.2f' % mean_absolute_error(y_test, predicted),\n",
      "        'mean_sqrd_err_reg_loss': '%0.2f' % mean_squared_error(y_test, predicted),\n",
      "        'r2_score': '%0.2f' % r2_score(y_test, predicted),\n",
      "        }\n",
      "        # fit model to full training set\n",
      "        self.model.fit(self.Xs, self.ys)\n",
      "        \n",
      "        return scores\n",
      "    \n",
      "    def dim_reduc_chart(self):\n",
      "        pca = PCA()\n",
      "        pca.fit(self.Xs)\n",
      "        \n",
      "        fig = plt.figure()\n",
      "        chart = fig.add_subplot(111)\n",
      "        chart.plot(pca.explained_variance_, linewidth=2)\n",
      "        chart.axis('tight')\n",
      "        chart.set_xlabel('N Components')\n",
      "        chart.set_ylabel('Explained Variance')\n",
      "        chart.set_title('Dimension Explanation')\n",
      "        \n",
      "    def iter_cross_val(self, classification=False):\n",
      "        # performs multiple cross-validation tests on data and returns averaged accuracy\n",
      "        # data set is kept in chronological order and devided into equal parts, or folds\n",
      "        # if data set is split into folds numbered: [1,2,3,4,5]\n",
      "        # the training / testing split follows this pattern:\n",
      "        # train[1] / test[2]\n",
      "        # train[1,2] / test[3]\n",
      "        # train[1,2,3] / test[4]\n",
      "        # train[1,2,3,4] / test[5]\n",
      "        \n",
      "        number_folds = 5\n",
      "        k = int(np.floor(float(self.Xs.shape[0]) / number_folds))\n",
      "        \n",
      "        if not classification:\n",
      "            bank_explained_variance_score = np.zeros(number_folds-1)\n",
      "            bank_mean_absolute_error = np.zeros(number_folds-1)\n",
      "            bank_mean_sqrd_err_reg_loss = np.zeros(number_folds-1)\n",
      "            bank_r2_score = np.zeros(number_folds-1)\n",
      "        else:\n",
      "            bank_accuracy = np.zeros(number_folds-1)\n",
      "            bank_log_loss = np.zeros(number_folds-1)\n",
      "        \n",
      "        for i in range(2, number_folds + 1):\n",
      "            split = float(i-1)/i\n",
      "            X = self.Xs[:(k*i)]\n",
      "            y = self.ys[:(k*i)]\n",
      "            index = int(np.floor(X.shape[0] * split))\n",
      "            \n",
      "            # folds used to train the model        \n",
      "            X_trainFolds = X[:index]        \n",
      "            y_trainFolds = y[:index]\n",
      "\n",
      "            # fold used to test the model\n",
      "            X_testFold = X[(index + 1):]\n",
      "            y_testFold = y[(index + 1):]\n",
      "            \n",
      "            self.model.fit (X_trainFolds, y_trainFolds)\n",
      "            \n",
      "            predicted = self.model.predict(X_testFold)\n",
      "\n",
      "            if not classification:\n",
      "                bank_explained_variance_score[i-2] = explained_variance_score(y_testFold, predicted)\n",
      "                bank_mean_absolute_error[i-2] = mean_absolute_error(y_testFold, predicted)\n",
      "                bank_mean_sqrd_err_reg_loss[i-2] = mean_squared_error(y_testFold, predicted)\n",
      "                bank_r2_score[i-2] = r2_score(y_testFold, predicted)\n",
      "            else:\n",
      "                predicted_proba = self.model.predict_proba(X_testFold)\n",
      "                #score = self.model.score(X_testFold, y_testFold)    \n",
      "                #scores[i-2] = score\n",
      "                bank_accuracy[i-2] = accuracy_score(y_testFold, predicted)\n",
      "                bank_log_loss[i-2] = log_loss(y_testFold, predicted_proba)\n",
      "\n",
      "        # fit model to full training set\n",
      "        self.model.fit(self.Xs, self.ys)\n",
      "        \n",
      "        if not classification:\n",
      "            return {\n",
      "            'explained_variance_score': '%0.2f (+/- %0.2f)' % (bank_explained_variance_score.mean(), bank_explained_variance_score.std() * 2), \n",
      "            'mean_absolute_error': '%0.2f (+/- %0.2f)' % (bank_mean_absolute_error.mean(), bank_mean_absolute_error.std() * 2), \n",
      "            'mean_sqrd_err_reg_loss': '%0.2f (+/- %0.2f)' % (bank_mean_sqrd_err_reg_loss.mean(), bank_mean_sqrd_err_reg_loss.std() * 2), \n",
      "            'r2_score': '%0.2f (+/- %0.2f)' % (bank_r2_score.mean(), bank_r2_score.std() * 2), \n",
      "            }\n",
      "        else:\n",
      "            return {\n",
      "                'accuracy_score': '%0.2f (+/- %0.2f)' % (bank_accuracy.mean(), bank_accuracy.std() * 2),\n",
      "                'log_loss': '%0.2f (+/- %0.2f)' % (bank_log_loss.mean(), bank_log_loss.std() * 2),\n",
      "            }\n",
      "    \n",
      "    def iter_cross_val_pred_probs_threshold_inds(self, threshold=0):\n",
      "        # performs multiple cross-validation tests on data and returns indices by classification - 0 or 1\n",
      "        # threshold setting ensures only predictions of a certain confidence will be returned\n",
      "        \n",
      "        # data set is kept in chronological order and devided into equal parts, or folds\n",
      "        # if data set is split into folds numbered: [1,2,3,4,5]\n",
      "        # the training / testing split follows this pattern:\n",
      "        # train[1] / test[2]\n",
      "        # train[1,2] / test[3]\n",
      "        # train[1,2,3] / test[4]\n",
      "        # train[1,2,3,4] / test[5]\n",
      "        \n",
      "        number_folds = 5\n",
      "        k = int(np.floor(float(self.Xs.shape[0]) / number_folds))\n",
      "        \n",
      "        \n",
      "        increase = []\n",
      "        decrease = []\n",
      "        fold_size = []\n",
      "        \n",
      "        for i in range(2, number_folds + 1):\n",
      "            split = float(i-1)/i\n",
      "            X = self.Xs[:(k*i)]\n",
      "            y = self.ys[:(k*i)]\n",
      "            index = int(np.floor(X.shape[0] * split))\n",
      "            \n",
      "            # folds used to train the model        \n",
      "            X_trainFolds = X[:index]        \n",
      "            y_trainFolds = y[:index]\n",
      "\n",
      "            # fold used to test the model\n",
      "            X_testFold = X[(index):]\n",
      "            y_testFold = y[(index):]\n",
      "            \n",
      "            self.model.fit (X_trainFolds, y_trainFolds)\n",
      "        \n",
      "            predicted_proba = self.model.predict_proba(X_testFold)\n",
      "   \n",
      "            inc = np.where(predicted_proba[:,1] > 0.5 + threshold)[0]\n",
      "            inc += index\n",
      "            increase.append(inc)\n",
      "            \n",
      "            dec = np.where(predicted_proba[:,1] < 0.5 - threshold)[0]\n",
      "            dec += index\n",
      "            decrease.append(dec)\n",
      "            \n",
      "            fold_size.append(X_testFold.shape[0])\n",
      "\n",
      "        # fit model to full training set\n",
      "        self.model.fit(self.Xs, self.ys)\n",
      "        \n",
      "        \n",
      "        return {\n",
      "                'increase': increase,\n",
      "                'decrease': decrease,\n",
      "                'fold_size': fold_size,\n",
      "                }\n",
      "\n",
      "    \n",
      "def test_classifier(model, test_set, y_col, X_cols):\n",
      "    # test classifier model on new data\n",
      "    ys = test_set[y_col].values\n",
      "    Xs = test_set[X_cols].values\n",
      "    Xs = model.preprocess_Xs(Xs)\n",
      "    predicted = model.model.predict(Xs)\n",
      "    print \"Accuracy: %f\" % (accuracy_score(ys, predicted))\n",
      "    predicted_proba = model.model.predict_proba(Xs)\n",
      "    print \"Log Loss: %f\" % (log_loss(ys, predicted_proba))\n",
      "    \n",
      "def test_pred_probs_threshold_inds(model, test_set, X_cols, threshold=0.0):\n",
      "    # get indices that meet prediction confidence threshold\n",
      "    Xs = test_set[X_cols].values\n",
      "    Xs = model.preprocess_Xs(Xs)\n",
      "    \n",
      "    predicted_proba = model.model.predict_proba(Xs)\n",
      "    \n",
      "    inc = np.where(predicted_proba[:,1] > 0.5 + threshold)[0]\n",
      "\n",
      "    dec = np.where(predicted_proba[:,1] < 0.5 - threshold)[0]\n",
      "    \n",
      "    return {\n",
      "            'increase': inc,\n",
      "            'decrease': dec,\n",
      "            'test_size': Xs.shape[0],\n",
      "            }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 516
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load source code data into a Pandas dataframe\n",
      "data = pd.read_csv('source/GDP_USA.csv', index_col=0, parse_dates=True)\n",
      "GDP_USA = pd.DataFrame(data)\n",
      "data = pd.read_csv('source/usa_aggr_monthly.csv', index_col=0)\n",
      "usa_aggr_monthly = pd.DataFrame(data)\n",
      "data = pd.read_csv('source/usa_cons_monthly.csv', index_col=0)\n",
      "usa_cons_monthly = pd.DataFrame(data)\n",
      "data = pd.read_csv('source/usa_cred_monthly.csv', index_col=0)\n",
      "usa_cred_monthly = pd.DataFrame(data)\n",
      "data = pd.read_csv('source/usa_real_monthly.csv', index_col=0)\n",
      "usa_real_monthly = pd.DataFrame(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 517
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# combine dataframes into one master dataframe, indexed by date\n",
      "master = pd.concat([\n",
      "                    GDP_USA.ix[:,:], \n",
      "                    usa_aggr_monthly.ix[:,:],\n",
      "                    usa_cons_monthly.ix[:,:],\n",
      "                    usa_cred_monthly.ix[:,:],\n",
      "                    usa_real_monthly.ix[:,:],\n",
      "                    ], \n",
      "                   axis=1)\n",
      "\n",
      "# convert date index to python datetime\n",
      "from dateutil.parser import parse\n",
      "dates = master.index.values\n",
      "dates = dates * 100 + 1\n",
      "dates = np.array(map(str, dates))\n",
      "dates = np.array(map(parse, dates))\n",
      "master.index = dates\n",
      "\n",
      "# simple series to visualize forecast data\n",
      "forecasts = master.ix[:,0]\n",
      "forecasts = forecasts.dropna(how='any')\n",
      "\n",
      "# remove rows where Y (forecast GDP) is NaN\n",
      "master = master.ix[forecasts.index]\n",
      "\n",
      "# remove features with missing data\n",
      "master_wo_missing = master.dropna(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 518
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lagged features\n",
      "shifted = master_wo_missing.shift(1)\n",
      "shifted = shifted.fillna(method='bfill')\n",
      "shifted = shifted.fillna(method='ffill')\n",
      "\n",
      "# one period change ratio\n",
      "change = master_wo_missing / shifted\n",
      "change = change.replace([np.inf, -np.inf], 0)\n",
      "change = change.replace(np.nan, 0)\n",
      "\n",
      "change.rename(columns=lambda x: \"%s-change\" % (x), inplace=True)\n",
      "shifted.rename(columns=lambda x: \"%s-lag\" % (x), inplace=True)\n",
      "\n",
      "# build exponentially weighted moving average for and each feature\n",
      "ewma = pd.stats.moments.ewma\n",
      "EMOV_n = ewma(master_wo_missing, com=5)\n",
      "EMOV_n.rename(columns=lambda x: \"%s-EWMA\" % (x), inplace=True)\n",
      "\n",
      "# build exponentially weighted moving average for changes in forecasts\n",
      "EMOV_change = ewma(change, com=5)\n",
      "EMOV_change.rename(columns=lambda x: \"%s-EWMA-change\" % (x), inplace=True)\n",
      "\n",
      "master_w_changes_and_lags = pd.concat([\n",
      "                                        master_wo_missing, \n",
      "                                        shifted, \n",
      "                                        change,\n",
      "                                        EMOV_n,\n",
      "                                        EMOV_change,\n",
      "                                        ],\n",
      "                                        axis=1)\n",
      "\n",
      "# remove the meta features relating to GDP Forecasts\n",
      "master_w_changes_and_lags_no_GDP = master_w_changes_and_lags.drop('USA GDP Revisions-EWMA', 1)\n",
      "master_w_changes_and_lags_no_GDP = master_w_changes_and_lags_no_GDP.drop('USA GDP Revisions-change', 1)\n",
      "master_w_changes_and_lags_no_GDP = master_w_changes_and_lags_no_GDP.drop('USA GDP Revisions-lag', 1)\n",
      "#master_w_changes_and_lags_no_GDP = master_w_changes_and_lags_no_GDP.drop('USA GDP Revisions-EWMA-change', 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 519
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add feature to indicate whether forecast increased or decreased since previous period\n",
      "fwd_GDP = master_w_changes_and_lags_no_GDP.ix[:,'USA GDP Revisions'].shift(-1)\n",
      "GDP = master_w_changes_and_lags_no_GDP.ix[:,'USA GDP Revisions']\n",
      "raw_increase = fwd_GDP - GDP\n",
      "raw_increase = raw_increase.dropna(how='any')\n",
      "bin_increase = raw_increase.map(lambda x: 1 if x > 0 else 0)\n",
      "bin_increase.name = \"GDP Forecast Increase\"\n",
      "\n",
      "\n",
      "master_dir_change = pd.concat([\n",
      "                    bin_increase,\n",
      "                    master_w_changes_and_lags_no_GDP.ix[bin_increase.index], \n",
      "                    ], \n",
      "                   axis=1)\n",
      "master_dir_change = master_dir_change.drop('USA GDP Revisions', 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 520
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select subset of rows for testing and model verification\n",
      "import math\n",
      "sample_count = int(math.floor(len(master_dir_change)*0.20))\n",
      "test_set = master_dir_change.ix[-sample_count:]\n",
      "train_set = master_dir_change.ix[:-sample_count-1]\n",
      "\n",
      "# prepare for building time series features\n",
      "cols = master_dir_change.columns\n",
      "y_col = cols[0]\n",
      "X_cols = cols[1:]\n",
      "ys = train_set[y_col].values\n",
      "Xs = train_set[X_cols].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 521
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "# implement simple grid search to find best hyper-parameters\n",
      "Cs = np.array([.01, .1, 1, 10,])\n",
      "Dims = np.array([None])\n",
      "for c in Cs:\n",
      "    for d in Dims:\n",
      "        print \"C: %s, Dimensions: %s\" % (c, d)\n",
      "        model = Model(Xs, ys, LogisticRegression(C=c), components=d)\n",
      "        scores = model.iter_cross_val(classification=True)\n",
      "        print \"accuracy score: %s, log_loss: %s\" % (scores['accuracy_score'] ,scores['log_loss'])\n",
      "        print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C: 0.01, Dimensions: None\n",
        "accuracy score: 0.66 (+/- 0.21), log_loss: 0.60 (+/- 0.14)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "C: 0.1, Dimensions: None\n",
        "accuracy score: 0.61 (+/- 0.15), log_loss: 0.76 (+/- 0.20)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "C: 1.0, Dimensions: None\n",
        "accuracy score: 0.60 (+/- 0.16), log_loss: 1.15 (+/- 0.27)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "C: 10.0, Dimensions: None\n",
        "accuracy score: 0.60 (+/- 0.22), log_loss: 1.67 (+/- 0.39)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 522
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test fitted model on new data\n",
      "model = Model(Xs, ys, LogisticRegression(C=.01))\n",
      "model.model.fit(model.Xs, ys)\n",
      "test_classifier(model, test_set, y_col, X_cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.627119\n",
        "Log Loss: 0.670860\n"
       ]
      }
     ],
     "prompt_number": 523
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Track market index changes from beginning of month to end of month. Confirm relationship between changes in GDP forecast and index changes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = master_dir_change.index[0]\n",
      "end = master_dir_change.index[-1] + datetime.timedelta(weeks=5)\n",
      "\n",
      "monthly_changes = pd.DataFrame()\n",
      "# index trackers (Dow Jones not available through yahoo or google)\n",
      "for i in ('^GSPC', '^IXIC'):\n",
      "    df = web.DataReader(i, 'yahoo', start, end)\n",
      "    \"\"\"\n",
      "    value = df[['Close','Volume']].prod(axis=1).resample('M', how=\"sum\")\n",
      "    tot_vol = df.Volume.resample('M', how=\"sum\")\n",
      "    vwap = value / tot_vol\n",
      "    change = vwap / vwap.shift(-1) - 1\n",
      "    \"\"\"\n",
      "    monthly = df.resample('M', how=\"ohlc\")\n",
      "    change = monthly.Open.close / monthly.Open.open - 1\n",
      "    #change = change.dropna(how='any')\n",
      "    monthly_changes[i] = change\n",
      "\n",
      "# change naming of index to match GDP forecast indexing\n",
      "monthly_changes.index = (monthly_changes.index + datetime.timedelta(days=1)).shift(-1)\n",
      "\n",
      "# find correlation between GDP Forecast changes and index-wide monthly returns over a one-month period\n",
      "# this correlation should only be calculated for training set, and should ignore test set information \n",
      "print \"GDP Forecast Change / Nasdaq correlation: %0.02f\" % (raw_increase.corr(monthly_changes['^IXIC']))\n",
      "print \"GDP Forecast Change / S&P correlation: %0.02f\" % (raw_increase.corr(monthly_changes['^GSPC']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GDP Forecast Change / Nasdaq correlation: 0.35\n",
        "GDP Forecast Change / S&P correlation: 0.38\n"
       ]
      }
     ],
     "prompt_number": 529
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Simulate buying long and short positions on market indexes when model predicts GDP Forecasts to increase or decrease with a given level of confidence. Use this information to select appropate confidence threshold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find indexes of GDP Forecasts where model expects Forecasts to decrease and increase with a given confidnece level (i.e. threshold)\n",
      "# threshold of 0.2 means only select rows where model is either 70% (0.5 + 0.2) confident forecast will increase or decrease\n",
      "# as model sees more data, we'd expect it to make predictions that meet threshold more often\n",
      "# predictions that meet threshold are labeled as actions and represent a time to buy and hold a security (long or short) for one month\n",
      "model = Model(Xs, ys, LogisticRegression(C=.01),)\n",
      "\n",
      "thresholds = [.0, .15, .25, .35,]\n",
      "for t in thresholds:\n",
      "    print \"Only act if %s percent confident -\" % (int((.5+t)*100))\n",
      "    preds = model.iter_cross_val_pred_probs_threshold_inds(threshold=t)\n",
      "    for i in range(len(preds['decrease'])):\n",
      "        print \"\\tCross val fold #%s\" % (i+1)\n",
      "        incs = monthly_changes.ix[preds['increase'][i]].mean(axis=1)\n",
      "        decs = monthly_changes.ix[preds['decrease'][i]].mean(axis=1)\n",
      "\n",
      "        # calculate weighted average gain per long and short position\n",
      "        p1 = incs.mean() * incs.shape[0] if incs.shape[0] else 0\n",
      "        p2 = (decs.mean() * - 1) * decs.shape[0] if decs.shape[0] else 0\n",
      "        wag = (p1 + p2) / (incs.shape[0] + decs.shape[0])\n",
      "        print \"\\tWeighted average gain (per action): %0.2f\" % (wag)\n",
      "    \n",
      "        # calculate annualized return\n",
      "        actions = (incs.shape[0] + decs.shape[0]) * 1.0\n",
      "        action_ratio = actions / preds['fold_size'][i]\n",
      "        monthly_return = wag * guess_ratio\n",
      "        print \"\\tAnnualized monthly return (w/o compounding): %0.2f\" % (monthly_return * 12)\n",
      "    print \"\"\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Only act if 50 percent confident -\n",
        "\tCross val fold #1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWeighted average gain (per action): 0.00\n",
        "\tAnnualized monthly return (w/o compounding): 0.00\n",
        "\tCross val fold #2\n",
        "\tWeighted average gain (per action): 0.00\n",
        "\tAnnualized monthly return (w/o compounding): 0.01\n",
        "\tCross val fold #3\n",
        "\tWeighted average gain (per action): 0.00\n",
        "\tAnnualized monthly return (w/o compounding): 0.00\n",
        "\tCross val fold #4\n",
        "\tWeighted average gain (per action): 0.01\n",
        "\tAnnualized monthly return (w/o compounding): 0.03\n",
        "\n",
        "Only act if 65 percent confident -\n",
        "\tCross val fold #1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWeighted average gain (per action): -0.01\n",
        "\tAnnualized monthly return (w/o compounding): -0.02\n",
        "\tCross val fold #2\n",
        "\tWeighted average gain (per action): 0.00\n",
        "\tAnnualized monthly return (w/o compounding): 0.00\n",
        "\tCross val fold #3\n",
        "\tWeighted average gain (per action): 0.01\n",
        "\tAnnualized monthly return (w/o compounding): 0.03\n",
        "\tCross val fold #4\n",
        "\tWeighted average gain (per action): 0.01\n",
        "\tAnnualized monthly return (w/o compounding): 0.04\n",
        "\n",
        "Only act if 75 percent confident -\n",
        "\tCross val fold #1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWeighted average gain (per action): -0.02\n",
        "\tAnnualized monthly return (w/o compounding): -0.06\n",
        "\tCross val fold #2\n",
        "\tWeighted average gain (per action): -0.02\n",
        "\tAnnualized monthly return (w/o compounding): -0.06\n",
        "\tCross val fold #3\n",
        "\tWeighted average gain (per action): 0.01\n",
        "\tAnnualized monthly return (w/o compounding): 0.05\n",
        "\tCross val fold #4\n",
        "\tWeighted average gain (per action): 0.03\n",
        "\tAnnualized monthly return (w/o compounding): 0.11\n",
        "\n",
        "Only act if 85 percent confident -\n",
        "\tCross val fold #1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWeighted average gain (per action): -0.02\n",
        "\tAnnualized monthly return (w/o compounding): -0.06\n",
        "\tCross val fold #2\n",
        "\tWeighted average gain (per action): -0.04\n",
        "\tAnnualized monthly return (w/o compounding): -0.15\n",
        "\tCross val fold #3\n",
        "\tWeighted average gain (per action): 0.02\n",
        "\tAnnualized monthly return (w/o compounding): 0.05\n",
        "\tCross val fold #4\n",
        "\tWeighted average gain (per action): 0.04\n",
        "\tAnnualized monthly return (w/o compounding): 0.14\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 528
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test performance of model on test data set with selected threshold of 0.35"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find test set data meeting prediction confidence threshold\n",
      "model = Model(Xs, ys, LogisticRegression(C=.01))\n",
      "model.model.fit(model.Xs, ys)\n",
      "inds = test_pred_probs_threshold_inds(model, test_set, X_cols, threshold=.35)\n",
      "\n",
      "# find date indices from test set reprsenting predicted increases and decreases meeting threshold\n",
      "inc_inds = test_set.index[inds['increase']]\n",
      "dec_inds = test_set.index[inds['decrease']]\n",
      "\n",
      "incs = monthly_changes.ix[inc_inds].mean(axis=1)\n",
      "decs = monthly_changes.ix[dec_inds].mean(axis=1)\n",
      "\n",
      "# calculate weighted average gain per long and short position\n",
      "p1 = incs.mean() * incs.shape[0] if incs.shape[0] else 0\n",
      "p2 = (decs.mean() * - 1) * decs.shape[0] if decs.shape[0] else 0\n",
      "wag = (p1 + p2) / (incs.shape[0] + decs.shape[0])\n",
      "print \"Weighted average gain (per action): %0.2f\" % (wag)\n",
      "\n",
      "# calculate the annualized return \n",
      "actions = (incs.shape[0] + decs.shape[0]) * 1.0\n",
      "action_ratio = actions / inds['test_size']\n",
      "monthly_return = wag * guess_ratio\n",
      "print \"Annualized monthly return (w/o compounding): %0.2f\" % (monthly_return * 12)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Weighted average gain (per action): 0.02\n",
        "Annualized monthly return (w/o compounding): 0.09\n"
       ]
      }
     ],
     "prompt_number": 527
    }
   ],
   "metadata": {}
  }
 ]
}